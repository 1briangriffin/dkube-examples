{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import kfp\n",
    "from dkube.sdk import *\n",
    "from dkube.pipelines import dkube_training_op, dkube_preprocessing_op, dkube_serving_op, dkube_storage_op, dkube_submit_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\")\n",
    "client = kfp.Client(existing_token=token)\n",
    "api = DkubeApi(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project owner resources\n",
    "project_id = os.environ.get(\"DKUBE_PROJECT_ID\", \"wprz8s\")\n",
    "project_name = os.environ.get(\"DKUBE_PROJECT_NAME\",\"titanic\")\n",
    "project_owner = os.environ.get(\"DKUBE_PROJECT_OWNER\",\"ocdkube\")\n",
    "username = os.getenv(\"USERNAME\",\"ocdkube\")\n",
    "ptrain_dataset = f'{project_owner}:titanic-train'\n",
    "ptest_dataset = f'{project_owner}:titanic-test'\n",
    "\n",
    "# User resources\n",
    "code_name = f'{project_name}-code'\n",
    "train_fs_name = f\"{project_name}-train-fs-{username}\"\n",
    "test_fs_name = f\"{project_name}-test-fs-{username}\"\n",
    "model_name = f'{project_name}-model'\n",
    "\n",
    "# Program specific variables\n",
    "image = \"docker.io/ocdr/dkube-datascience-tf-cpu:fs-v2.0.0\"\n",
    "dataset_mount_points = [\"/dataset/train\", \"/dataset/test\"]\n",
    "output_featureset_mount_points = [\"/featureset/train\", \"/featureset/test\"]\n",
    "preprocessing_script = f\"python titanic/preprocess.py --train_fs {train_fs_name} --test_fs {test_fs_name}\"\n",
    "training_script = \"python training.py\"\n",
    "train_inp_mount_points = [\"/titanic-train\",\"/titanic-test\"]\n",
    "train_out_mount_points = [\"/model\"]\n",
    "runid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create code repo \n",
    "code = DkubeCode(username,code_name)\n",
    "code.update_git_details(url=\"https://github.com/oneconvergence/dkube-examples-2.0.git\", branch=\"tensorflow\")\n",
    "api.create_code(code)\n",
    "#Create train/test featureset\n",
    "api.create_featureset(DkubeFeatureSet(train_fs_name))\n",
    "api.create_featureset(DkubeFeatureSet(test_fs_name))\n",
    "#Create model\n",
    "api.create_model(DkubeModel(username, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='dkube-titanic-pl',\n",
    "    description='example titanic pipeline to submit to leaderboard'\n",
    ")\n",
    "def titanic_pipeline(token, project_id):\n",
    "    preprocessing = dkube_preprocessing_op(token, json.dumps({\"image\": image}),\n",
    "                                            tags=json.dumps([f\"project:{project_id}\"]),\n",
    "                                            program=code_name, run_script=preprocessing_script,\n",
    "                                            datasets=json.dumps([ptrain_dataset, ptest_dataset]), \n",
    "                                            output_featuresets=json.dumps([train_fs_name, test_fs_name]),\n",
    "                                            input_dataset_mounts=json.dumps(dataset_mount_points), \n",
    "                                            output_featureset_mounts=json.dumps(output_featureset_mount_points)\n",
    "\n",
    "    with kfp.dsl.ExitHandler(exit_op=dkube_storage_op(\"reclaim\", token)):\n",
    "        train       = dkube_training_op(token, json.dumps({\"image\": image}),\n",
    "                                        tags=json.dumps([f\"project:{project_id}\"]),\n",
    "                                        framework=\"sklearn\", version=\"0.23.2\",\n",
    "                                        program=code_name, run_script=training_script,\n",
    "                                        featuresets=json.dumps([train_fs_name, test_fs_name]), outputs=json.dumps([model_name]),\n",
    "                                        input_featureset_mounts=json.dumps(train_inp_mount_points),\n",
    "                                        output_mounts=json.dumps(train_out_mount_points)).after(preprocessing)\n",
    "        input_volumes = json.dumps([\n",
    "                                    \"{{workflow.uid}}-model@model://\" + model_name,\n",
    "                                    \"{{workflow.uid}}-code@program://\" + code_name,\n",
    "                                    \"{{workflow.uid}}-featureset@featureset://\" + test_fs_name\n",
    "                                    ])\n",
    "\n",
    "        storage  = dkube_storage_op(\"export\", token , input_volumes=input_volumes).after(train)\n",
    "    \n",
    "        predict_op = kfp.dsl.ContainerOp(\n",
    "            name=\"predict\", image=image,\n",
    "            command=[\"python\", \"/code/titanic/predict.py\"],\n",
    "            pvolumes={\n",
    "                     \"/model/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-model\"),\n",
    "                     \"/code/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-code\"),\n",
    "                     \"/test_fs/\": kfp.dsl.PipelineVolume(pvc=\"{{workflow.uid}}-featureset\")\n",
    "                     },\n",
    "            file_outputs={\"output\": \"/tmp/prediction.csv\"},\n",
    "        ).after(storage)\n",
    "\n",
    "        predictions = kfp.dsl.InputArgumentPath(predict_op.outputs[\"output\"])\n",
    "        submit = dkube_submit_op(token, project_id, predictions=predict_op.outputs[\"output\"]).after(predict_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_run_from_pipeline_func(titanic_pipeline, run_name=\"[titanic] Run\" + str(runid), arguments={\"token\":token,\"project_id\":project_id})\n",
    "runid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfp.compiler.Compiler().compile(titanic_pipeline, \"titanic_pipeline.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}