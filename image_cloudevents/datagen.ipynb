{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import requests, json\n",
    "from numpy import random\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = ('.jpg', 'jpeg', '.png', '.svg')\n",
    "\n",
    "class ImageData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_data_from_dir(self, imagedir, grayscale=True, read_labels=False):\n",
    "        image_files = list()\n",
    "        for file_type in image_types:\n",
    "            image_files.extend(glob.glob(os.path.join(imagedir, \"**/*\" + file_type), recursive=True))\n",
    "        if len(image_files) == 0:\n",
    "            return None\n",
    "        images = []\n",
    "        for each_image_file in image_files:\n",
    "            if grayscale:\n",
    "                img = cv2.imread(each_image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                img = cv2.imread(each_image_file)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        train_x = np.asarray(images)\n",
    "        if read_labels:\n",
    "            csv_files = glob.glob(os.path.join(imagedir, \"**/*\" + \".csv\"), recursive=True)\n",
    "            label_data = pd.read_csv(csv_files[-1])\n",
    "            train_y = label_data.iloc[:,-1:].values\n",
    "            return train_x, train_y\n",
    "        else:\n",
    "            return train_x\n",
    "\n",
    "    def read_classification_data(self, datadir):\n",
    "        train_x = list()\n",
    "        train_y = list()\n",
    "        for dp, dn, filenames in os.walk(datadir):\n",
    "            if len(filenames) > 0:\n",
    "                current_class_data = self.read_data_from_dir(dp)\n",
    "                train_x.extend(current_class_data)\n",
    "                train_y.extend([os.path.basename(dp)] * current_class_data.shape[0])\n",
    "        if len(train_x) == 0:\n",
    "            return None\n",
    "        train_x = np.asarray(train_x)\n",
    "        train_y = np.asarray(train_y)\n",
    "        train_y_classes, train_y = np.unique(train_y, return_inverse=True)\n",
    "        return train_x, (train_y_classes, train_y)\n",
    "\n",
    "    def resize_images(self, images, new_shape):\n",
    "        resized_images = []\n",
    "        for each_image in images:\n",
    "            resized_images.append(cv2.resize(each_image, new_shape, interpolation= cv2.INTER_LINEAR))\n",
    "        resized_images = np.asarray(resized_images)\n",
    "        return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd = ImageData()\n",
    "train_x, train_y = imd.read_classification_data(\"data/\")\n",
    "train_y_classes, train_y = train_y\n",
    "resized_train_x = imd.resize_images(train_x, (200,200))\n",
    "resized_train_x = resized_train_x.reshape(resized_train_x.shape[0], 200, 200, 1)\n",
    "resized_train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(resized_train_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "resized_train_x = resized_train_x[indices]\n",
    "train_y = train_y[indices]\n",
    "resized_train_x.shape, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_url = INFERENCE_URL\n",
    "token = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    random.shuffle(resized_train_x)\n",
    "    ch = random.choice(range(resized_train_x.shape[0]))\n",
    "    x = resized_train_x[ch:ch+1]\n",
    "    payload = {\n",
    "        \"inputs\": {'input_1': x.tolist()}\n",
    "    }\n",
    "    r = requests.post(predict_url, json=payload, headers = {'authorization': \"Bearer \" + token}, verify = False)\n",
    "    prediction = json.loads(r.content.decode('utf-8'))\n",
    "    outputs = np.array(prediction[\"outputs\"])\n",
    "    outputs = train_y_classes[outputs.argmax(axis=1)].tolist()\n",
    "    \n",
    "    start = datetime.datetime.utcnow()\n",
    "    end = start + datetime.timedelta(seconds=10)\n",
    "    timestamps = pd.date_range(start, end, len(outputs))\n",
    "    labels = train_y_classes[train_y[ch:ch+1]].tolist()\n",
    "    labelled_df = pd.DataFrame({\n",
    "        \"timestamp\": timestamps,\n",
    "        \"output\": outputs,\n",
    "        \"label\": labels\n",
    "    })\n",
    "    print(labelled_df)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
